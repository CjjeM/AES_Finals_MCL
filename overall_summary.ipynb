{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import language_tool_python\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, BayesianRidge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor, RandomForestRegressor\n",
    "from time import sleep\n",
    "from threading import Thread\n",
    "import time\n",
    "import re\n",
    "from textstat import flesch_reading_ease\n",
    "\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persuasive/Narrative/Expository Essays Summary\n",
    "## Essay Set 1, 2, 7, 8\n",
    "\n",
    "Features Used\n",
    "- Topic Relevance\n",
    "    - LSA (TF-IDF) Matrix\n",
    "    - Cosine similarity between an essay to the top scoring essays by their TruncatedSVD Matrix\n",
    "- Word Usage and Sentence complexity\n",
    "    - Number of words, Sentences, Unique words, Average word length\n",
    "    - Parts-Of-Speech Tagging\n",
    "- Grammar and Mechanics\n",
    "    - Language Tool (number of mistakes)\n",
    "- Readability (Text Complexity)\n",
    "    - Flesch Reading Ease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thread for LanguageTool\n",
    "class LanguageCorrect(Thread):\n",
    "    def __init__(self, df, idx, lt_servers):\n",
    "        Thread.__init__(self)\n",
    "        self.value = None\n",
    "        self.df = df\n",
    "        self.index = idx\n",
    "        self.lt_servers = lt_servers\n",
    " \n",
    "    def run(self):\n",
    "        self.df['essay'] = self.df['essay'].apply(self.autocorrect_essay)\n",
    "        self.value = self.df\n",
    "        return\n",
    "    \n",
    "    def autocorrect_essay(self, essay):\n",
    "        corrected_essay = self.lt_servers[self.index].correct(essay)\n",
    "        return corrected_essay\n",
    "\n",
    "class LanguageCheck(Thread):\n",
    "    def __init__(self, df, idx, lt_servers):\n",
    "        Thread.__init__(self)\n",
    "        self.value = None\n",
    "        self.df = df\n",
    "        self.index = idx\n",
    "        self.lt_servers = lt_servers\n",
    "\n",
    "    def run(self):\n",
    "        self.df['grammar_errors'] = self.df['essay'].apply(self.grammar_errors)\n",
    "        self.value = self.df\n",
    "        return\n",
    "    \n",
    "    def grammar_errors(self, essay):\n",
    "        errors = self.lt_servers[self.index].check(essay)\n",
    "        return len(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# essay structure\n",
    "\n",
    "def word_count(essay):\n",
    "    clean_essay = re.sub(r'\\W', ' ', essay)\n",
    "    words = nltk.word_tokenize(clean_essay)\n",
    "\n",
    "    return len(words)\n",
    "\n",
    "def unique_word_count(essay):\n",
    "    clean_essay = re.sub(r'\\W', ' ', essay)\n",
    "    words = nltk.word_tokenize(clean_essay)\n",
    "    unique_words = set(words)\n",
    "\n",
    "    return len(unique_words)\n",
    "\n",
    "def sentence_count(essay):\n",
    "    sentences = nltk.sent_tokenize(essay)\n",
    "    \n",
    "    return len(sentences)\n",
    "\n",
    "def avg_word_len(essay):\n",
    "    clean_essay = re.sub(r'\\W', ' ', essay)\n",
    "    words = nltk.word_tokenize(clean_essay)\n",
    "    \n",
    "    return sum(len(word) for word in words) / len(words)\n",
    "\n",
    "\n",
    "def sentence_to_wordlist(raw_sentence):\n",
    "    \n",
    "    clean_sentence = re.sub(\"[^a-zA-Z0-9]\",\" \", raw_sentence)\n",
    "    tokens = nltk.word_tokenize(clean_sentence)\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "def tokenize(essay):\n",
    "    stripped_essay = essay.strip()\n",
    "    \n",
    "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    raw_sentences = tokenizer.tokenize(stripped_essay)\n",
    "    \n",
    "    tokenized_sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        if len(raw_sentence) > 0:\n",
    "            tokenized_sentences.append(sentence_to_wordlist(raw_sentence))\n",
    "    \n",
    "    return tokenized_sentences\n",
    "\n",
    "def count_pos(essay):\n",
    "    \n",
    "    tokenized_sentences = tokenize(essay)\n",
    "    \n",
    "    noun_count = 0\n",
    "    adj_count = 0\n",
    "    verb_count = 0\n",
    "    adv_count = 0\n",
    "    \n",
    "    for sentence in tokenized_sentences:\n",
    "        tagged_tokens = nltk.pos_tag(sentence)\n",
    "        \n",
    "        for token_tuple in tagged_tokens:\n",
    "            pos_tag = token_tuple[1]\n",
    "        \n",
    "            if pos_tag.startswith('N'): \n",
    "                noun_count += 1\n",
    "            elif pos_tag.startswith('J'):\n",
    "                adj_count += 1\n",
    "            elif pos_tag.startswith('V'):\n",
    "                verb_count += 1\n",
    "            elif pos_tag.startswith('R'):\n",
    "                adv_count += 1\n",
    "            \n",
    "    return noun_count, adj_count, verb_count, adv_count\n",
    "\n",
    "\n",
    "def readability_score(essay):\n",
    "    score = flesch_reading_ease(essay)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataframe(essay_set):\n",
    "    lt_servers = []\n",
    "    for _ in range(5):\n",
    "        lt_servers.append(language_tool_python.LanguageTool('en-US'))\n",
    "\n",
    "    thread_list = []\n",
    "\n",
    "    df = pd.read_excel(\"training_set_rel3.xls\")\n",
    "    df = df[df[\"essay_set\"]==essay_set]\n",
    "\n",
    "    print(f\"Retrieving Essay Set #{essay_set}\")\n",
    "    print(f\"Dataframe shape: {df.shape}\")\n",
    "\n",
    "    clean_df = df[['essay', 'domain1_score']].copy()\n",
    "    clean_df = clean_df.rename(columns={'domain1_score': 'actual_score'})\n",
    "\n",
    "    if essay_set == 2:\n",
    "        clean_df = df[['essay', 'domain1_score', 'domain2_score']].copy()\n",
    "        clean_df['actual_score'] = clean_df['domain1_score'] + clean_df['domain2_score']\n",
    "        clean_df.drop(['domain1_score', 'domain2_score'], axis=1, inplace=True)\n",
    "\n",
    "    # get essay structure\n",
    "    print(\"Getting Word Count\")\n",
    "    clean_df['word_count'] = clean_df['essay'].apply(word_count)\n",
    "    print(\"Getting Unique Word Count\")\n",
    "    clean_df['unique_word_count'] = clean_df['essay'].apply(unique_word_count)\n",
    "    print(\"Getting Sentence Count\")\n",
    "    clean_df['sentence_count'] = clean_df['essay'].apply(sentence_count)\n",
    "    print(\"Getting Average Word Length\")\n",
    "    clean_df['avg_word_len'] = clean_df['essay'].apply(avg_word_len)\n",
    "    print(\"POS Tagging\")\n",
    "    clean_df['noun_count'], clean_df['adj_count'], clean_df['verb_count'], clean_df['adv_count'] = zip(*clean_df['essay'].map(count_pos))\n",
    "    print(\"Getting Readability\")\n",
    "    clean_df['readability_score'] = clean_df['essay'].apply(readability_score)\n",
    "\n",
    "    # get grammatical errors\n",
    "    print(\"Getting Grammatical Errors\")\n",
    "    df_split = np.array_split(clean_df, len(lt_servers))\n",
    "    # put threads into list\n",
    "    for idx, i in enumerate(df_split):\n",
    "        thread_langcheck = LanguageCheck(df=i, idx=idx, lt_servers=lt_servers)\n",
    "        thread_list.append(thread_langcheck)\n",
    "\n",
    "    # start thread list\n",
    "    for thread in thread_list:\n",
    "        thread.start()\n",
    "\n",
    "    # join all threads\n",
    "    for thread in thread_list:\n",
    "        thread.join()\n",
    "    \n",
    "    clean_df = pd.concat([thread.value for thread in thread_list], axis=0)\n",
    "    \n",
    "    thread_list.clear()\n",
    "\n",
    "    # autocorrect errors\n",
    "    print(\"Autocorrecting Essay\")\n",
    "    df_split = np.array_split(clean_df, len(lt_servers))\n",
    "    # put threads into list\n",
    "    for idx, i in enumerate(df_split):\n",
    "        thread_langcheck = LanguageCorrect(df=i, idx=idx, lt_servers=lt_servers)\n",
    "        thread_list.append(thread_langcheck)\n",
    "\n",
    "    # start thread list\n",
    "    for thread in thread_list:\n",
    "        thread.start()\n",
    "\n",
    "    # join all threads\n",
    "    for thread in thread_list:\n",
    "        thread.join()\n",
    "    \n",
    "    clean_df = pd.concat([thread.value for thread in thread_list], axis=0)\n",
    "\n",
    "    for tool in lt_servers:\n",
    "        tool.close()\n",
    "    \n",
    "    thread_list.clear()\n",
    "    lt_servers.clear()\n",
    "\n",
    "    # preprocess essay for tokenization\n",
    "    print(\"Preprocess for tokenization\")\n",
    "    clean_df.reset_index(drop=True, inplace=True)\n",
    "    clean_df['essay'] = clean_df['essay'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "    clean_df['essay'] = clean_df['essay'].apply(lambda x: x.lower())\n",
    "\n",
    "    # tokenization\n",
    "    print(\"Tokenization Start\")\n",
    "    tokenized_doc = clean_df['essay'].apply(lambda x: x.split())\n",
    "\n",
    "    # remove stop-words\n",
    "    print(\"Removing Stop Words\")\n",
    "    tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])\n",
    "\n",
    "    # stemming\n",
    "    print(\"Word Stemming\")\n",
    "    porter_stemmer = PorterStemmer()\n",
    "    tokenized_doc = tokenized_doc.apply(lambda x: [porter_stemmer.stem(item) for item in x])\n",
    "\n",
    "    # de-tokenization\n",
    "    print(\"Detokenize\")\n",
    "    detokenized_doc = []\n",
    "    for i in range(len(clean_df)):\n",
    "        t = ' '.join(tokenized_doc[i])\n",
    "        detokenized_doc.append(t)\n",
    "\n",
    "    clean_df['essay'] = detokenized_doc\n",
    "\n",
    "    return clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorization_process(df, sample_essays, max_features):\n",
    "    df_lsa = df.copy()\n",
    "    largest_possible_score = df_lsa.nlargest(1, 'actual_score')['actual_score'].values[0]\n",
    "\n",
    "    top_score = largest_possible_score - (largest_possible_score * 0.10)\n",
    "\n",
    "    chosen_essay = df_lsa[df_lsa['actual_score'] >= top_score]\n",
    "    chosen_essay = chosen_essay.groupby('actual_score').sample(sample_essays, random_state=26)\n",
    "\n",
    "    df_lsa = df_lsa.drop(index = chosen_essay.index)\n",
    "\n",
    "    # Create a vectorizer for lsa similarity\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "    # Vectorize document using TF-IDF\n",
    "    tfidf_lsa_vectorizer = TfidfVectorizer(lowercase=True,\n",
    "                                            stop_words='english',\n",
    "                                            ngram_range = (1,3),\n",
    "                                            tokenizer = tokenizer.tokenize)\n",
    "\n",
    "    tfidf_lsa_matrix = tfidf_lsa_vectorizer.fit_transform(chosen_essay[\"essay\"])\n",
    "\n",
    "    # TFIDF to SVD\n",
    "    svd_lsa_model = TruncatedSVD(n_components=100,\n",
    "                            n_iter=200,\n",
    "                            random_state=69)\n",
    "        \n",
    "    svd_lsa = svd_lsa_model.fit_transform(tfidf_lsa_matrix)\n",
    "    normalized_svd = Normalizer(copy=False).fit_transform(svd_lsa)\n",
    "\n",
    "    def lsa_score(essay):\n",
    "        essay_matrix = tfidf_lsa_vectorizer.transform([essay])\n",
    "        essay_svd = svd_lsa_model.transform(essay_matrix)\n",
    "        normalized_essay_svd = Normalizer(copy=False).fit_transform(essay_svd)\n",
    "\n",
    "        # Compare current essay to the top 10% scored essay\n",
    "        similarities = cosine_similarity(normalized_svd, normalized_essay_svd).max()\n",
    "\n",
    "        return similarities.max()\n",
    "    \n",
    "    df_lsa['lsa_score'] = df_lsa['essay'].apply(lsa_score)\n",
    "\n",
    "    # Create a vectorizer for the training data\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "    # Vectorize document using TF-IDF\n",
    "    tfidf_vectorizer = TfidfVectorizer(lowercase=True,\n",
    "                                    stop_words='english',\n",
    "                                    ngram_range = (1,3),\n",
    "                                    tokenizer = tokenizer.tokenize,\n",
    "                                    max_features=max_features)\n",
    "\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(df_lsa[\"essay\"])\n",
    "\n",
    "    # TFIDF to SVD\n",
    "    svd_model = TruncatedSVD(n_components=100,\n",
    "                            n_iter=200,\n",
    "                            random_state=69)\n",
    "        \n",
    "    svd = svd_model.fit_transform(tfidf_matrix)\n",
    "\n",
    "    return df_lsa, svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_process(df_lsa, svd):\n",
    "    print(\"Getting Features\")\n",
    "    x_df_features = df_lsa[['word_count', \n",
    "                            'unique_word_count',\n",
    "                            'sentence_count',\n",
    "                            'avg_word_len',\n",
    "                            'grammar_errors',\n",
    "                            'lsa_score', \n",
    "                            'readability_score',\n",
    "                            'noun_count',\n",
    "                            'adj_count',\n",
    "                            'verb_count',\n",
    "                            'adv_count']]\n",
    "\n",
    "    x_features = np.concatenate((x_df_features.to_numpy(), svd), axis=1)\n",
    "    y_features = df_lsa['actual_score'].to_numpy()\n",
    "\n",
    "    print(\"Splitting Dataset\")\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_features, y_features, test_size = 0.2, train_size = 0.8, random_state = 420)\n",
    "\n",
    "    print(\"Building Linear Regression Model\")\n",
    "    lr_model = LinearRegression()\n",
    "    lr_model.fit(x_train, y_train)\n",
    "\n",
    "    print(\"Building SVR Model\")\n",
    "    svr_model = SVR()\n",
    "    svr_model.fit(x_train, y_train)\n",
    "\n",
    "    print(\"Building Decision Tree Model\")\n",
    "    tree_model = DecisionTreeRegressor()\n",
    "    tree_model.fit(x_train, y_train)\n",
    "\n",
    "    print(\"Building Bayesian Regressor\")\n",
    "    bayes_model = BayesianRidge()\n",
    "    bayes_model.fit(x_train, y_train)\n",
    "\n",
    "    print(\"Building AdaBoost Regressor\")\n",
    "    ada_model = AdaBoostRegressor(n_estimators=100)\n",
    "    ada_model.fit(x_train, y_train)\n",
    "\n",
    "    print(\"Building Random Forest Regressor\")\n",
    "    ran_model = RandomForestRegressor()\n",
    "    ran_model.fit(x_train, y_train)\n",
    "\n",
    "    print(\"Building Gradient Boosting Regressor\")\n",
    "    grad_model = GradientBoostingRegressor(n_estimators=200)\n",
    "    grad_model.fit(x_train, y_train)\n",
    "\n",
    "    print(\"Building Logistic Regression Model\")\n",
    "    log_model = LogisticRegression(solver=\"saga\", max_iter=10000)\n",
    "    log_model.fit(x_train, y_train)\n",
    "\n",
    "    print(\"Getting Predictions\")\n",
    "    predictions = [ lr_model.predict(x_test),\n",
    "                    svr_model.predict(x_test),\n",
    "                    tree_model.predict(x_test),\n",
    "                    bayes_model.predict(x_test),\n",
    "                    ada_model.predict(x_test),\n",
    "                    ran_model.predict(x_test),\n",
    "                    grad_model.predict(x_test),\n",
    "                    log_model.predict(x_test)]\n",
    "    scores = []\n",
    "    \n",
    "    for idx, pred in enumerate(predictions):\n",
    "        mae = mean_absolute_error(y_test, pred)\n",
    "        mse = mean_squared_error(y_test, pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r_score = r2_score(y_test, pred)\n",
    "\n",
    "        scores.append([idx, mae, mse, rmse, r_score])\n",
    "    \n",
    "    print(\"\\nResults:\")\n",
    "    best_score = max(scores, key=lambda sublist: sublist[-1])\n",
    "    print(f\"Model {best_score[0]}\")\n",
    "    print(f\"Mean Absolute Error: {best_score[1]}\")\n",
    "    print(f\"Mean Squared Error: {best_score[2]}\")\n",
    "    print(f\"Root Mean Squared Error: {best_score[3]}\")\n",
    "    print(f\"R2 score: {best_score[4]}\\n\")\n",
    "\n",
    "    print(\"Cross Validation 10-Folds\")\n",
    "\n",
    "    kf = KFold(n_splits=10)\n",
    "\n",
    "    scores = [cross_val_score(lr_model, x_features, y_features, cv=kf).mean(),\n",
    "          cross_val_score(svr_model, x_features, y_features, cv=kf).mean(),\n",
    "          cross_val_score(tree_model, x_features, y_features, cv=kf).mean(),\n",
    "          cross_val_score(bayes_model, x_features, y_features, cv=kf).mean(),\n",
    "          cross_val_score(ada_model, x_features, y_features, cv=kf).mean(),\n",
    "          cross_val_score(ran_model, x_features, y_features, cv=kf).mean(),\n",
    "          cross_val_score(grad_model, x_features, y_features, cv=kf).mean(),\n",
    "          cross_val_score(log_model, x_features, y_features, cv=kf).mean()]\n",
    "    \n",
    "    print(f\"Model {scores.index(max(scores))}\")\n",
    "    print(f\"Overall Score: {max(scores)}\\n\")\n",
    "\n",
    "    return best_score, (scores.index(max(scores)), max(scores))# average_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocess Start\n",
      "Retrieving Essay Set #1\n",
      "Dataframe shape: (1783, 28)\n",
      "Getting Word Count\n",
      "Getting Unique Word Count\n",
      "Getting Sentence Count\n",
      "Getting Average Word Length\n",
      "POS Tagging\n",
      "Getting Readability\n",
      "Getting Grammatical Errors\n",
      "Autocorrecting Essay\n",
      "Preprocess for tokenization\n",
      "Tokenization Start\n",
      "Removing Stop Words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chaldea\\AppData\\Local\\Temp\\ipykernel_1056\\3942059866.py:83: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  clean_df['essay'] = clean_df['essay'].str.replace(\"[^a-zA-Z#]\", \" \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Stemming\n",
      "Detokenize\n",
      "Vectorization Start\n",
      "Training Start\n",
      "Getting Features\n",
      "Splitting Dataset\n",
      "Building Linear Regression Model\n",
      "Building SVR Model\n",
      "Building Decision Tree Model\n",
      "Building Bayesian Regressor\n",
      "Building AdaBoost Regressor\n",
      "Building Random Forest Regressor\n",
      "Building Gradient Boosting Regressor\n",
      "Building Logistic Regression Model\n",
      "Getting Predictions\n",
      "\n",
      "Results:\n",
      "Model 5\n",
      "Mean Absolute Error: 0.5931728045325778\n",
      "Mean Squared Error: 0.5577917847025495\n",
      "Root Mean Squared Error: 0.746854594082777\n",
      "R2 score: 0.7728462200885008\n",
      "\n",
      "Cross Validation 10-Folds\n",
      "Model 1\n",
      "Overall Score: 0.7318932133096692\n",
      "\n",
      "\n",
      "\n",
      "Preprocess Start\n",
      "Retrieving Essay Set #2\n",
      "Dataframe shape: (1800, 28)\n",
      "Getting Word Count\n",
      "Getting Unique Word Count\n",
      "Getting Sentence Count\n",
      "Getting Average Word Length\n",
      "POS Tagging\n",
      "Getting Readability\n",
      "Getting Grammatical Errors\n",
      "Autocorrecting Essay\n",
      "Preprocess for tokenization\n",
      "Tokenization Start\n",
      "Removing Stop Words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chaldea\\AppData\\Local\\Temp\\ipykernel_1056\\3942059866.py:83: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  clean_df['essay'] = clean_df['essay'].str.replace(\"[^a-zA-Z#]\", \" \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Stemming\n",
      "Detokenize\n",
      "Vectorization Start\n",
      "Training Start\n",
      "Getting Features\n",
      "Splitting Dataset\n",
      "Building Linear Regression Model\n",
      "Building SVR Model\n",
      "Building Decision Tree Model\n",
      "Building Bayesian Regressor\n",
      "Building AdaBoost Regressor\n",
      "Building Random Forest Regressor\n",
      "Building Gradient Boosting Regressor\n",
      "Building Logistic Regression Model\n",
      "Getting Predictions\n",
      "\n",
      "Results:\n",
      "Model 6\n",
      "Mean Absolute Error: 0.6484774183609476\n",
      "Mean Squared Error: 0.6747706545099783\n",
      "Root Mean Squared Error: 0.8214442491794427\n",
      "R2 score: 0.5977613666762005\n",
      "\n",
      "Cross Validation 10-Folds\n",
      "Model 6\n",
      "Overall Score: 0.6286681761170474\n",
      "\n",
      "\n",
      "\n",
      "Preprocess Start\n",
      "Retrieving Essay Set #7\n",
      "Dataframe shape: (1569, 28)\n",
      "Getting Word Count\n",
      "Getting Unique Word Count\n",
      "Getting Sentence Count\n",
      "Getting Average Word Length\n",
      "POS Tagging\n",
      "Getting Readability\n",
      "Getting Grammatical Errors\n",
      "Autocorrecting Essay\n",
      "Preprocess for tokenization\n",
      "Tokenization Start\n",
      "Removing Stop Words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chaldea\\AppData\\Local\\Temp\\ipykernel_1056\\3942059866.py:83: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  clean_df['essay'] = clean_df['essay'].str.replace(\"[^a-zA-Z#]\", \" \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Stemming\n",
      "Detokenize\n",
      "Vectorization Start\n",
      "Training Start\n",
      "Getting Features\n",
      "Splitting Dataset\n",
      "Building Linear Regression Model\n",
      "Building SVR Model\n",
      "Building Decision Tree Model\n",
      "Building Bayesian Regressor\n",
      "Building AdaBoost Regressor\n",
      "Building Random Forest Regressor\n",
      "Building Gradient Boosting Regressor\n",
      "Building Logistic Regression Model\n",
      "Getting Predictions\n",
      "\n",
      "Results:\n",
      "Model 6\n",
      "Mean Absolute Error: 2.0788689025580025\n",
      "Mean Squared Error: 6.874569049361013\n",
      "Root Mean Squared Error: 2.621939940075099\n",
      "R2 score: 0.6652576217071945\n",
      "\n",
      "Cross Validation 10-Folds\n",
      "Model 6\n",
      "Overall Score: 0.6322037224022616\n",
      "\n",
      "\n",
      "\n",
      "Preprocess Start\n",
      "Retrieving Essay Set #8\n",
      "Dataframe shape: (723, 28)\n",
      "Getting Word Count\n",
      "Getting Unique Word Count\n",
      "Getting Sentence Count\n",
      "Getting Average Word Length\n",
      "POS Tagging\n",
      "Getting Readability\n",
      "Getting Grammatical Errors\n",
      "Autocorrecting Essay\n",
      "Preprocess for tokenization\n",
      "Tokenization Start\n",
      "Removing Stop Words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chaldea\\AppData\\Local\\Temp\\ipykernel_1056\\3942059866.py:83: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  clean_df['essay'] = clean_df['essay'].str.replace(\"[^a-zA-Z#]\", \" \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Stemming\n",
      "Detokenize\n",
      "Vectorization Start\n",
      "Training Start\n",
      "Getting Features\n",
      "Splitting Dataset\n",
      "Building Linear Regression Model\n",
      "Building SVR Model\n",
      "Building Decision Tree Model\n",
      "Building Bayesian Regressor\n",
      "Building AdaBoost Regressor\n",
      "Building Random Forest Regressor\n",
      "Building Gradient Boosting Regressor\n",
      "Building Logistic Regression Model\n",
      "Getting Predictions\n",
      "\n",
      "Results:\n",
      "Model 5\n",
      "Mean Absolute Error: 2.9186896551724137\n",
      "Mean Squared Error: 14.778853103448276\n",
      "Root Mean Squared Error: 3.8443273928540838\n",
      "R2 score: 0.5665732280751676\n",
      "\n",
      "Cross Validation 10-Folds\n",
      "Model 5\n",
      "Overall Score: 0.5403300813474997\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# not source summary\n",
    "# (essay_set, sample_essay, max_features)\n",
    "summaries = [(1, 10, 10000),\n",
    "            (2, 5, 10000), \n",
    "            (7, 10, 10000), \n",
    "            (8, 1, 1000)]\n",
    "\n",
    "summary_scores = []\n",
    "\n",
    "for summary in summaries:\n",
    "    print(\"Preprocess Start\")\n",
    "    clean_df = preprocess_dataframe(summary[0])\n",
    "    \n",
    "    print(\"Vectorization Start\")\n",
    "    df_lsa, svd = vectorization_process(clean_df, summary[1], summary[2])\n",
    "    \n",
    "    print(\"Training Start\")\n",
    "    best_score, average_score = training_process(df_lsa, svd)\n",
    "\n",
    "    summary_scores.append([best_score, average_score])\n",
    "\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models were chosen based on the highest R2 Score\n",
    "\n",
    "### Essay Set 1\n",
    "Results: <br>\n",
    "Model 5 (Random Forest)<br>\n",
    "Mean Absolute Error: 0.5931728045325778<br>\n",
    "Mean Squared Error: 0.5577917847025495<br>\n",
    "Root Mean Squared Error: 0.746854594082777<br>\n",
    "R2 score: 0.7728462200885008<br>\n",
    "\n",
    "Cross Validation 10-Folds<br>\n",
    "Model 1 (Support Vector Machine)<br>\n",
    "Overall Score: 0.7318932133096692<br>\n",
    "\n",
    "### Essay Set 2\n",
    "Results: <br>\n",
    "Model 6 (Gradient Boosting)<br>\n",
    "Mean Absolute Error: 0.6484774183609476<br>\n",
    "Mean Squared Error: 0.6747706545099783<br>\n",
    "Root Mean Squared Error: 0.8214442491794427<br>\n",
    "R2 score: 0.5977613666762005<br>\n",
    "\n",
    "Cross Validation 10-Folds<br>\n",
    "Model 6 (Gradient Boosting)<br>\n",
    "Overall Score: 0.6286681761170474<br>\n",
    "\n",
    "### Essay Set 7\n",
    "Results: <br>\n",
    "Model 6 (Gradient Boosting)<br>\n",
    "Mean Absolute Error: 2.0788689025580025<br>\n",
    "Mean Squared Error: 6.874569049361013<br>\n",
    "Root Mean Squared Error: 2.621939940075099<br>\n",
    "R2 score: 0.6652576217071945<br>\n",
    "\n",
    "Cross Validation 10-Folds <br>\n",
    "Model 6 (Gradient Boosting)<br>\n",
    "Overall Score: 0.6322037224022616<br>\n",
    "\n",
    "### Essay Set 8\n",
    "Results: <br>\n",
    "Model 5 (Random Forest)<br>\n",
    "Mean Absolute Error: 2.9186896551724137<br>\n",
    "Mean Squared Error: 14.778853103448276<br>\n",
    "Root Mean Squared Error: 3.8443273928540838<br>\n",
    "R2 score: 0.5665732280751676<br>\n",
    "\n",
    "Cross Validation 10-Folds<br>\n",
    "Model 5 (Random Forest)<br>\n",
    "Overall Score: 0.5403300813474997<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source Dependent Essays Summary\n",
    "## Essay Set 3, 4, 5, 6\n",
    "\n",
    "Features Used\n",
    "- Topic Relevance\n",
    "    - LSA (TF-IDF) Matrix\n",
    "    - Cosine similarity between an essay to the top scoring essays and the source essay by their TruncatedSVD Matrix\n",
    "- Word Usage and Sentence complexity\n",
    "    - Number of words, Sentences, Unique words, Average word length\n",
    "    - Parts-Of-Speech Tagging\n",
    "- Grammar and Mechanics\n",
    "    - Language Tool (number of mistakes)\n",
    "- Readability (Text Complexity)\n",
    "    - Flesch Reading Ease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1d888b7e27d9d4f8fccada6ae7e4260d620cc5227dee391d6d7538000bf76028"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
