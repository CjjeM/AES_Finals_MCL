{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import language_tool_python\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, BayesianRidge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor, RandomForestRegressor\n",
    "\n",
    "language_tool = language_tool_python.LanguageTool('en-US')\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"training_set_rel3.xls\")\n",
    "essay_set = 6\n",
    "df = df[df[\"essay_set\"] == essay_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(essay):\n",
    "    clean_essay = re.sub(r'\\W', ' ', essay)\n",
    "    words = nltk.word_tokenize(essay)\n",
    "    return len(words)\n",
    "\n",
    "def unique_word_count(essay):\n",
    "    clean_essay = re.sub(r'\\W', ' ', essay)\n",
    "    words = nltk.word_tokenize(clean_essay)\n",
    "    unique_words = set(words)\n",
    "    return len(unique_words)\n",
    "\n",
    "def sentence_count(essay):\n",
    "    sentences = nltk.sent_tokenize(essay)\n",
    "    return len(sentences)\n",
    "\n",
    "def avg_word_len(essay):\n",
    "    clean_essay = re.sub(r'\\W', ' ', essay)\n",
    "    words = nltk.word_tokenize(clean_essay)\n",
    "    return sum(len(word) for word in words) / len(words)\n",
    "\n",
    "def grammar_errors(essay):\n",
    "    errors = language_tool.check(essay)\n",
    "    return len(errors)\n",
    "\n",
    "def autocorrect_essay(essay):\n",
    "    corrected_essay = language_tool.correct(essay)\n",
    "    return corrected_essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_dataframe(df):\n",
    "    clean_df = df[['essay', 'domain1_score']].copy()\n",
    "    clean_df = clean_df.rename(columns={'domain1_score': 'actual_score'})\n",
    "\n",
    "    print(\"Getting Word Count\")\n",
    "    clean_df['word_count'] = clean_df['essay'].apply(word_count)\n",
    "    print(\"Getting Unique Word Count\")\n",
    "    clean_df['unique_word_count'] = clean_df['essay'].apply(unique_word_count)\n",
    "    print(\"Getting Sentence Count\")\n",
    "    clean_df['sentence_count'] = clean_df['essay'].apply(sentence_count)\n",
    "    print(\"Getting Average Word Length\")\n",
    "    clean_df['avg_word_len'] = clean_df['essay'].apply(avg_word_len)\n",
    "\n",
    "    print(\"Getting Grammatical Errors\")\n",
    "    clean_df['grammar_errors'] = clean_df['essay'].apply(grammar_errors)\n",
    "\n",
    "    print(\"Autocorrecting Essay\")\n",
    "    clean_df['essay'] = clean_df['essay'].apply(autocorrect_essay)\n",
    "\n",
    "    print(\"Preprocess for tokenization\")\n",
    "    clean_df.reset_index(drop=True, inplace=True)\n",
    "    clean_df['essay'] = clean_df['essay'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "    clean_df['essay'] = clean_df['essay'].apply(lambda x: x.lower())\n",
    "\n",
    "    print(\"Tokenization Start\")\n",
    "    tokenized_doc = clean_df['essay'].apply(lambda x: x.split())\n",
    "\n",
    "    print(\"Removing Stop Words\")\n",
    "    tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])\n",
    "\n",
    "    print(\"Word Stemming\")\n",
    "    porter_stemmer = PorterStemmer()\n",
    "    tokenized_doc = tokenized_doc.apply(lambda x: [porter_stemmer.stem(item) for item in x])\n",
    "\n",
    "    print(\"Detokenize\")\n",
    "    detokenized_doc = []\n",
    "    for i in range(len(clean_df)):\n",
    "        t = ' '.join(tokenized_doc[i])\n",
    "        detokenized_doc.append(t)\n",
    "\n",
    "    clean_df['essay'] = detokenized_doc\n",
    "\n",
    "    return clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Word Count\n",
      "Getting Unique Word Count\n",
      "Getting Sentence Count\n",
      "Getting Average Word Length\n",
      "Getting Grammatical Errors\n",
      "Autocorrecting Essay\n",
      "Preprocess for tokenization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mark Anthony Mamauag\\AppData\\Local\\Temp\\ipykernel_15580\\3993004738.py:22: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  clean_df['essay'] = clean_df['essay'].str.replace(\"[^a-zA-Z#]\", \" \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization Start\n",
      "Removing Stop Words\n",
      "Word Stemming\n",
      "Detokenize\n"
     ]
    }
   ],
   "source": [
    "main_df = define_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>When the Empire State Building was conceived, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_set                                              essay\n",
       "0          6  When the Empire State Building was conceived, ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source = pd.read_csv('source_essays.txt', sep=\"|\", header=None)\n",
    "stacked_source = source.stack().reset_index()\n",
    "source_essay = stacked_source.drop(['level_0', 'level_1'], axis=1).rename(columns={0: 'essay'})\n",
    "source_essay.insert(0, \"essay_set\", [6, 5, 4, 3], True)\n",
    "source_essay = source_essay.sort_values(by=['essay_set'], ascending=True)\n",
    "source_essay = source_essay.loc[source_essay['essay_set'] == essay_set]\n",
    "source_essay.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_source_essay(source_essay):\n",
    "    print(\"Preprocess for tokenization\")\n",
    "    source_essay['essay'] = source_essay['essay'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "    source_essay['essay'] = source_essay['essay'].apply(lambda x: x.lower())\n",
    "\n",
    "    print(\"Tokenization Start\")\n",
    "    tokenized_doc = source_essay['essay'].apply(lambda x: x.split())\n",
    "\n",
    "    print(\"Removing Stop Words\")\n",
    "    tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])\n",
    "\n",
    "    print(\"Word Stemming\")\n",
    "    porter_stemmer = PorterStemmer()\n",
    "    tokenized_doc = tokenized_doc.apply(lambda x: [porter_stemmer.stem(item) for item in x])\n",
    "\n",
    "    print(\"Detokenize\")\n",
    "    detokenized_doc = []\n",
    "    for i in range(len(source_essay)):\n",
    "        t = ' '.join(tokenized_doc[i])\n",
    "        detokenized_doc.append(t)\n",
    "\n",
    "    source_essay['essay'] = detokenized_doc\n",
    "\n",
    "    return source_essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocess for tokenization\n",
      "Tokenization Start\n",
      "Removing Stop Words\n",
      "Word Stemming\n",
      "Detokenize\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mark Anthony Mamauag\\AppData\\Local\\Temp\\ipykernel_15580\\213839504.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  source_essay['essay'] = source_essay['essay'].str.replace(\"[^a-zA-Z#]\", \" \")\n"
     ]
    }
   ],
   "source": [
    "cleaned_source_essay = clean_source_essay(source_essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay</th>\n",
       "      <th>actual_score</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>grammar_errors</th>\n",
       "      <th>essay_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mani obstacl builder face attempt dirig dock e...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.560976</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>start would mani problem allow dirig dock num ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.733333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>builder empir state build face mani obstacl at...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.491124</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>passag moor mast marcia amid cap builder empir...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.417085</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>builder empir state build face mani obstacl at...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.654321</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>problem construct dock dirig natur caus like h...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>builder empir state build face obstacl attempt...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.657143</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>obstacl builder empir state build could move e...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.485294</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>want tell go attempt allow dirig dock well tel...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.177215</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>empir state build conceiv plan world tallest b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1801 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  essay  actual_score  \\\n",
       "0     mani obstacl builder face attempt dirig dock e...           2.0   \n",
       "1     start would mani problem allow dirig dock num ...           3.0   \n",
       "2     builder empir state build face mani obstacl at...           4.0   \n",
       "3     passag moor mast marcia amid cap builder empir...           1.0   \n",
       "4     builder empir state build face mani obstacl at...           3.0   \n",
       "...                                                 ...           ...   \n",
       "1796  problem construct dock dirig natur caus like h...           2.0   \n",
       "1797  builder empir state build face obstacl attempt...           3.0   \n",
       "1798  obstacl builder empir state build could move e...           2.0   \n",
       "1799  want tell go attempt allow dirig dock well tel...           2.0   \n",
       "0     empir state build conceiv plan world tallest b...           NaN   \n",
       "\n",
       "      word_count  unique_word_count  sentence_count  avg_word_len  \\\n",
       "0          134.0               90.0             6.0      4.560976   \n",
       "1          201.0              116.0             9.0      4.733333   \n",
       "2          180.0              104.0             8.0      4.491124   \n",
       "3          213.0              118.0             7.0      4.417085   \n",
       "4          176.0               93.0            10.0      4.654321   \n",
       "...          ...                ...             ...           ...   \n",
       "1796        72.0               53.0             3.0      4.833333   \n",
       "1797       119.0               71.0             5.0      4.657143   \n",
       "1798        71.0               54.0             2.0      4.485294   \n",
       "1799       179.0               87.0             9.0      4.177215   \n",
       "0            NaN                NaN             NaN           NaN   \n",
       "\n",
       "      grammar_errors  essay_set  \n",
       "0                3.0        NaN  \n",
       "1                2.0        NaN  \n",
       "2                2.0        NaN  \n",
       "3               12.0        NaN  \n",
       "4                1.0        NaN  \n",
       "...              ...        ...  \n",
       "1796             2.0        NaN  \n",
       "1797             3.0        NaN  \n",
       "1798             2.0        NaN  \n",
       "1799             7.0        NaN  \n",
       "0                NaN        6.0  \n",
       "\n",
       "[1801 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = [main_df, cleaned_source_essay]\n",
    "combined_df = pd.concat(frames)\n",
    "\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay</th>\n",
       "      <th>actual_score</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>grammar_errors</th>\n",
       "      <th>essay_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mani obstacl builder face attempt dirig dock e...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.560976</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>start would mani problem allow dirig dock num ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.733333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>builder empir state build face mani obstacl at...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.491124</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>passag moor mast marcia amid cap builder empir...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.417085</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>builder empir state build face mani obstacl at...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.654321</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>problem construct dock dirig natur caus like h...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>builder empir state build face obstacl attempt...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.657143</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>obstacl builder empir state build could move e...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.485294</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>want tell go attempt allow dirig dock well tel...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.177215</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>empir state build conceiv plan world tallest b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1781 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  essay  actual_score  \\\n",
       "0     mani obstacl builder face attempt dirig dock e...           2.0   \n",
       "1     start would mani problem allow dirig dock num ...           3.0   \n",
       "2     builder empir state build face mani obstacl at...           4.0   \n",
       "3     passag moor mast marcia amid cap builder empir...           1.0   \n",
       "4     builder empir state build face mani obstacl at...           3.0   \n",
       "...                                                 ...           ...   \n",
       "1796  problem construct dock dirig natur caus like h...           2.0   \n",
       "1797  builder empir state build face obstacl attempt...           3.0   \n",
       "1798  obstacl builder empir state build could move e...           2.0   \n",
       "1799  want tell go attempt allow dirig dock well tel...           2.0   \n",
       "0     empir state build conceiv plan world tallest b...           NaN   \n",
       "\n",
       "      word_count  unique_word_count  sentence_count  avg_word_len  \\\n",
       "0          134.0               90.0             6.0      4.560976   \n",
       "1          201.0              116.0             9.0      4.733333   \n",
       "2          180.0              104.0             8.0      4.491124   \n",
       "3          213.0              118.0             7.0      4.417085   \n",
       "4          176.0               93.0            10.0      4.654321   \n",
       "...          ...                ...             ...           ...   \n",
       "1796        72.0               53.0             3.0      4.833333   \n",
       "1797       119.0               71.0             5.0      4.657143   \n",
       "1798        71.0               54.0             2.0      4.485294   \n",
       "1799       179.0               87.0             9.0      4.177215   \n",
       "0            NaN                NaN             NaN           NaN   \n",
       "\n",
       "      grammar_errors  essay_set  \n",
       "0                3.0        NaN  \n",
       "1                2.0        NaN  \n",
       "2                2.0        NaN  \n",
       "3               12.0        NaN  \n",
       "4                1.0        NaN  \n",
       "...              ...        ...  \n",
       "1796             2.0        NaN  \n",
       "1797             3.0        NaN  \n",
       "1798             2.0        NaN  \n",
       "1799             7.0        NaN  \n",
       "0                NaN        6.0  \n",
       "\n",
       "[1781 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_essay = combined_df[combined_df['actual_score'] >= 3]\n",
    "combined_essay = combined_essay.groupby('actual_score').sample(10, random_state=26)\n",
    "\n",
    "combined_df = combined_df.drop(index = combined_essay.index)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train TFIDF Matrix Shape: (20, 284)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tfidf_lsa_vectorizer = TfidfVectorizer(lowercase=True,\n",
    "                                        stop_words='english',\n",
    "                                        ngram_range = (1,3),\n",
    "                                        tokenizer = tokenizer.tokenize,\n",
    "                                        max_features=350,\n",
    "                                        max_df=0.8,\n",
    "                                        min_df=3)\n",
    "\n",
    "tfidf_lsa_matrix = tfidf_lsa_vectorizer.fit_transform(combined_essay[\"essay\"])\n",
    "print(f\"Train TFIDF Matrix Shape: {tfidf_lsa_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_lsa_model = TruncatedSVD(n_components=100,\n",
    "                         n_iter=200,\n",
    "                         random_state=69)\n",
    "    \n",
    "svd_lsa = svd_lsa_model.fit_transform(tfidf_lsa_matrix)\n",
    "normalized_svd = Normalizer(copy=False).fit_transform(svd_lsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lsa_score(essay):\n",
    "    essay_matrix = tfidf_lsa_vectorizer.transform([essay])\n",
    "\n",
    "    essay_svd = svd_lsa_model.transform(essay_matrix)\n",
    "    normalized_essay_svd = Normalizer(copy=False).fit_transform(essay_svd)\n",
    "\n",
    "    similarities = cosine_similarity(normalized_svd, normalized_essay_svd).max()\n",
    "\n",
    "    return similarities.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay</th>\n",
       "      <th>actual_score</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>grammar_errors</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>lsa_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mani obstacl builder face attempt dirig dock e...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.560976</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.589376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>start would mani problem allow dirig dock num ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.733333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.658643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>builder empir state build face mani obstacl at...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.491124</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.770081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>passag moor mast marcia amid cap builder empir...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.417085</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.620654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>builder empir state build face mani obstacl at...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.654321</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.772386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>problem construct dock dirig natur caus like h...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.665028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>builder empir state build face obstacl attempt...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.657143</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.630899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>obstacl builder empir state build could move e...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.485294</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.774887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>want tell go attempt allow dirig dock well tel...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.177215</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.645588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>empir state build conceiv plan world tallest b...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.693081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1781 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  essay  actual_score  \\\n",
       "0     mani obstacl builder face attempt dirig dock e...           2.0   \n",
       "1     start would mani problem allow dirig dock num ...           3.0   \n",
       "2     builder empir state build face mani obstacl at...           4.0   \n",
       "3     passag moor mast marcia amid cap builder empir...           1.0   \n",
       "4     builder empir state build face mani obstacl at...           3.0   \n",
       "...                                                 ...           ...   \n",
       "1796  problem construct dock dirig natur caus like h...           2.0   \n",
       "1797  builder empir state build face obstacl attempt...           3.0   \n",
       "1798  obstacl builder empir state build could move e...           2.0   \n",
       "1799  want tell go attempt allow dirig dock well tel...           2.0   \n",
       "0     empir state build conceiv plan world tallest b...           0.0   \n",
       "\n",
       "      word_count  unique_word_count  sentence_count  avg_word_len  \\\n",
       "0          134.0               90.0             6.0      4.560976   \n",
       "1          201.0              116.0             9.0      4.733333   \n",
       "2          180.0              104.0             8.0      4.491124   \n",
       "3          213.0              118.0             7.0      4.417085   \n",
       "4          176.0               93.0            10.0      4.654321   \n",
       "...          ...                ...             ...           ...   \n",
       "1796        72.0               53.0             3.0      4.833333   \n",
       "1797       119.0               71.0             5.0      4.657143   \n",
       "1798        71.0               54.0             2.0      4.485294   \n",
       "1799       179.0               87.0             9.0      4.177215   \n",
       "0            0.0                0.0             0.0      0.000000   \n",
       "\n",
       "      grammar_errors  essay_set  lsa_score  \n",
       "0                3.0        0.0   0.589376  \n",
       "1                2.0        0.0   0.658643  \n",
       "2                2.0        0.0   0.770081  \n",
       "3               12.0        0.0   0.620654  \n",
       "4                1.0        0.0   0.772386  \n",
       "...              ...        ...        ...  \n",
       "1796             2.0        0.0   0.665028  \n",
       "1797             3.0        0.0   0.630899  \n",
       "1798             2.0        0.0   0.774887  \n",
       "1799             7.0        0.0   0.645588  \n",
       "0                0.0        6.0   0.693081  \n",
       "\n",
       "[1781 rows x 9 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df['lsa_score'] = combined_df['essay'].apply(lsa_score)\n",
    "combined_df = combined_df.fillna(0)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train TFIDF Matrix Shape: (1781, 6098)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# VECTORIZER FOR: Training data\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tfidf_vectorizer = TfidfVectorizer(lowercase=True,\n",
    "                                   stop_words='english',\n",
    "                                   ngram_range = (1,3),\n",
    "                                   tokenizer = tokenizer.tokenize,\n",
    "                                   max_features=10000,\n",
    "                                   max_df=0.8,\n",
    "                                   min_df=5)\n",
    "\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(combined_df[\"essay\"])\n",
    "print(f\"Train TFIDF Matrix Shape: {tfidf_matrix.shape}\")\n",
    "svd_model = TruncatedSVD(n_components=100,\n",
    "                         n_iter=200,\n",
    "                         random_state=69)\n",
    "\n",
    "svd = svd_model.fit_transform(tfidf_matrix)\n",
    "print(type(svd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_df_features = combined_df[['word_count', 'unique_word_count', 'sentence_count', 'avg_word_len', 'grammar_errors', 'lsa_score']]\n",
    "\n",
    "x_features = np.concatenate((x_df_features.to_numpy(), svd), axis=1)\n",
    "y_features = combined_df['actual_score'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_features, y_features, test_size = 0.2, train_size = 0.8, random_state = 420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Linear Regression Model\n",
      "Building SVR Model\n",
      "Building Decision Tree Model\n",
      "Building Bayesian Regressor\n",
      "Building AdaBoost Regressor\n",
      "Building Random Forest Regressor\n",
      "Building Gradient Boosting Regressor\n",
      "Building Logistic Regression Model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=10000, solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000, solver=&#x27;saga&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=10000, solver='saga')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Building Linear Regression Model\")\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(x_train, y_train)\n",
    "\n",
    "print(\"Building SVR Model\")\n",
    "svr_model = SVR()\n",
    "svr_model.fit(x_train, y_train)\n",
    "\n",
    "print(\"Building Decision Tree Model\")\n",
    "tree_model = DecisionTreeRegressor()\n",
    "tree_model.fit(x_train, y_train)\n",
    "\n",
    "print(\"Building Bayesian Regressor\")\n",
    "bayes_model = BayesianRidge()\n",
    "bayes_model.fit(x_train, y_train)\n",
    "\n",
    "print(\"Building AdaBoost Regressor\")\n",
    "ada_model = AdaBoostRegressor(n_estimators=100)\n",
    "ada_model.fit(x_train, y_train)\n",
    "\n",
    "print(\"Building Random Forest Regressor\")\n",
    "ran_model = RandomForestRegressor()\n",
    "ran_model.fit(x_train, y_train)\n",
    "\n",
    "print(\"Building Gradient Boosting Regressor\")\n",
    "grad_model = GradientBoostingRegressor(n_estimators=200)\n",
    "grad_model.fit(x_train, y_train)\n",
    "\n",
    "print(\"Building Logistic Regression Model\")\n",
    "log_model = LogisticRegression(solver=\"saga\", max_iter=10000)\n",
    "log_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [lr_model.predict(x_test),\n",
    "               svr_model.predict(x_test),\n",
    "               tree_model.predict(x_test),\n",
    "               bayes_model.predict(x_test),\n",
    "               ada_model.predict(x_test),\n",
    "               ran_model.predict(x_test),\n",
    "               grad_model.predict(x_test),\n",
    "               log_model.predict(x_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0\n",
      "Mean Absolute Error: 0.4179766701514603\n",
      "Mean Squared Error: 0.27705123201788273\n",
      "Root Mean Squared Error: 0.5263565635744297\n",
      "R2 score: 0.7028586368196518\n",
      "\n",
      "Model 1\n",
      "Mean Absolute Error: 0.49692305073962595\n",
      "Mean Squared Error: 0.44865528420549466\n",
      "Root Mean Squared Error: 0.6698173513768471\n",
      "R2 score: 0.5188108647779547\n",
      "\n",
      "Model 2\n",
      "Mean Absolute Error: 0.5098039215686274\n",
      "Mean Squared Error: 0.6106442577030813\n",
      "Root Mean Squared Error: 0.7814373024773524\n",
      "R2 score: 0.34507540056550423\n",
      "\n",
      "Model 3\n",
      "Mean Absolute Error: 0.4148862176016638\n",
      "Mean Squared Error: 0.27066810071822184\n",
      "Root Mean Squared Error: 0.5202577252845189\n",
      "R2 score: 0.7097046353807337\n",
      "\n",
      "Model 4\n",
      "Mean Absolute Error: 0.44412564161380175\n",
      "Mean Squared Error: 0.3167705741978974\n",
      "Root Mean Squared Error: 0.5628237505630848\n",
      "R2 score: 0.6602590807951745\n",
      "\n",
      "Model 5\n",
      "Mean Absolute Error: 0.4153221288515406\n",
      "Mean Squared Error: 0.2894798319327731\n",
      "Root Mean Squared Error: 0.5380333000221948\n",
      "R2 score: 0.6895287877002827\n",
      "\n",
      "Model 6\n",
      "Mean Absolute Error: 0.4171795060531011\n",
      "Mean Squared Error: 0.2755308023232227\n",
      "Root Mean Squared Error: 0.5249102802605629\n",
      "R2 score: 0.7044893191624108\n",
      "\n",
      "Model 7\n",
      "Mean Absolute Error: 0.46218487394957986\n",
      "Mean Squared Error: 0.5742296918767507\n",
      "Root Mean Squared Error: 0.7577794480432619\n",
      "R2 score: 0.38413053722902923\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, pred in enumerate(predictions):\n",
    "    mae = mean_absolute_error(y_test, pred)\n",
    "    mse = mean_squared_error(y_test, pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r_score = r2_score(y_test, pred)\n",
    "\n",
    "    print(f\"Model {idx}\")\n",
    "    print(f\"Mean Absolute Error: {mae}\")\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    print(f\"Root Mean Squared Error: {rmse}\")\n",
    "    print(f\"R2 score: {r_score}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = [cross_val_score(lr_model, x_train, y_train, cv=10).mean(),\n",
    "          cross_val_score(svr_model, x_train, y_train, cv=10).mean(),\n",
    "          cross_val_score(tree_model, x_train, y_train, cv=10).mean(),\n",
    "          cross_val_score(bayes_model, x_train, y_train, cv=10).mean(),\n",
    "          cross_val_score(ada_model, x_train, y_train, cv=10).mean(),\n",
    "          cross_val_score(ran_model, x_train, y_train, cv=10).mean(),\n",
    "          cross_val_score(grad_model, x_train, y_train, cv=10).mean(),\n",
    "          cross_val_score(log_model, x_train, y_train, cv=10).mean()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 0\n",
      "Overall Score: 0.7204673236068857\n",
      "\n",
      "Model: 1\n",
      "Overall Score: 0.5125873393932061\n",
      "\n",
      "Model: 2\n",
      "Overall Score: 0.353916279625689\n",
      "\n",
      "Model: 3\n",
      "Overall Score: 0.7233026350033527\n",
      "\n",
      "Model: 4\n",
      "Overall Score: 0.6232416101511905\n",
      "\n",
      "Model: 5\n",
      "Overall Score: 0.6700420912002907\n",
      "\n",
      "Model: 6\n",
      "Overall Score: 0.6987423607990226\n",
      "\n",
      "Model: 7\n",
      "Overall Score: 0.5730424505072393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, score in enumerate(scores):\n",
    "    print(f\"Model: {idx}\")\n",
    "    print(f\"Overall Score: {score}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d4804b05511593ff5d39042ce4458bba250db19b4b42c28c2a085011e4afa5b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
