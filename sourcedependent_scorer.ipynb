{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import language_tool_python\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, BayesianRidge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor, RandomForestRegressor\n",
    "\n",
    "language_tool = language_tool_python.LanguageTool('en-US')\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"training_set_rel3.xls\")\n",
    "essay_set = 6\n",
    "df = df[df[\"essay_set\"] == essay_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(essay):\n",
    "    clean_essay = re.sub(r'\\W', ' ', essay)\n",
    "    words = nltk.word_tokenize(essay)\n",
    "    return len(words)\n",
    "\n",
    "def unique_word_count(essay):\n",
    "    clean_essay = re.sub(r'\\W', ' ', essay)\n",
    "    words = nltk.word_tokenize(clean_essay)\n",
    "    unique_words = set(words)\n",
    "    return len(unique_words)\n",
    "\n",
    "def sentence_count(essay):\n",
    "    sentences = nltk.sent_tokenize(essay)\n",
    "    return len(sentences)\n",
    "\n",
    "def avg_word_len(essay):\n",
    "    clean_essay = re.sub(r'\\W', ' ', essay)\n",
    "    words = nltk.word_tokenize(clean_essay)\n",
    "    return sum(len(word) for word in words) / len(words)\n",
    "\n",
    "def grammar_errors(essay):\n",
    "    errors = language_tool.check(essay)\n",
    "    return len(errors)\n",
    "\n",
    "def autocorrect_essay(essay):\n",
    "    corrected_essay = language_tool.correct(essay)\n",
    "    return corrected_essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_dataframe(df):\n",
    "    clean_df = df[['essay', 'domain1_score']].copy()\n",
    "    clean_df = clean_df.rename(columns={'domain1_score': 'actual_score'})\n",
    "\n",
    "    print(\"Getting Word Count\")\n",
    "    clean_df['word_count'] = clean_df['essay'].apply(word_count)\n",
    "    print(\"Getting Unique Word Count\")\n",
    "    clean_df['unique_word_count'] = clean_df['essay'].apply(unique_word_count)\n",
    "    print(\"Getting Sentence Count\")\n",
    "    clean_df['sentence_count'] = clean_df['essay'].apply(sentence_count)\n",
    "    print(\"Getting Average Word Length\")\n",
    "    clean_df['avg_word_len'] = clean_df['essay'].apply(avg_word_len)\n",
    "\n",
    "    print(\"Getting Grammatical Errors\")\n",
    "    clean_df['grammar_errors'] = clean_df['essay'].apply(grammar_errors)\n",
    "\n",
    "    print(\"Autocorrecting Essay\")\n",
    "    clean_df['essay'] = clean_df['essay'].apply(autocorrect_essay)\n",
    "\n",
    "    print(\"Preprocess for tokenization\")\n",
    "    clean_df.reset_index(drop=True, inplace=True)\n",
    "    clean_df['essay'] = clean_df['essay'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "    clean_df['essay'] = clean_df['essay'].apply(lambda x: x.lower())\n",
    "\n",
    "    print(\"Tokenization Start\")\n",
    "    tokenized_doc = clean_df['essay'].apply(lambda x: x.split())\n",
    "\n",
    "    print(\"Removing Stop Words\")\n",
    "    tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])\n",
    "\n",
    "    print(\"Word Stemming\")\n",
    "    porter_stemmer = PorterStemmer()\n",
    "    tokenized_doc = tokenized_doc.apply(lambda x: [porter_stemmer.stem(item) for item in x])\n",
    "\n",
    "    print(\"Detokenize\")\n",
    "    detokenized_doc = []\n",
    "    for i in range(len(clean_df)):\n",
    "        t = ' '.join(tokenized_doc[i])\n",
    "        detokenized_doc.append(t)\n",
    "\n",
    "    clean_df['essay'] = detokenized_doc\n",
    "\n",
    "    return clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Word Count\n",
      "Getting Unique Word Count\n",
      "Getting Sentence Count\n",
      "Getting Average Word Length\n",
      "Getting Grammatical Errors\n",
      "Autocorrecting Essay\n",
      "Preprocess for tokenization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mark Anthony Mamauag\\AppData\\Local\\Temp\\ipykernel_21320\\3993004738.py:22: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  clean_df['essay'] = clean_df['essay'].str.replace(\"[^a-zA-Z#]\", \" \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization Start\n",
      "Removing Stop Words\n",
      "Word Stemming\n",
      "Detokenize\n"
     ]
    }
   ],
   "source": [
    "main_df = define_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>FORGET THAT OLD SAYING ABOUT NEVER taking cand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Saeng, a teenage girl, and her family have mov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>My parents, originally from Cuba, arrived in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>When the Empire State Building was conceived, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_set                                              essay\n",
       "3          3  FORGET THAT OLD SAYING ABOUT NEVER taking cand...\n",
       "2          4  Saeng, a teenage girl, and her family have mov...\n",
       "1          5  My parents, originally from Cuba, arrived in t...\n",
       "0          6  When the Empire State Building was conceived, ..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source = pd.read_csv('source_essays.txt', sep=\"|\", header=None)\n",
    "stacked_source = source.stack().reset_index()\n",
    "source_essay = stacked_source.drop(['level_0', 'level_1'], axis=1).rename(columns={0: 'essay'})\n",
    "source_essay.insert(0, \"essay_set\", [6, 5, 4, 3], True)\n",
    "source_essay = source_essay.sort_values(by=['essay_set'], ascending=True)\n",
    "source_essay.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_source_essay(source_essay):\n",
    "    print(\"Preprocess for tokenization\")\n",
    "    source_essay['essay'] = source_essay['essay'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "    source_essay['essay'] = source_essay['essay'].apply(lambda x: x.lower())\n",
    "\n",
    "    print(\"Tokenization Start\")\n",
    "    tokenized_doc = source_essay['essay'].apply(lambda x: x.split())\n",
    "\n",
    "    print(\"Removing Stop Words\")\n",
    "    tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])\n",
    "\n",
    "    print(\"Word Stemming\")\n",
    "    porter_stemmer = PorterStemmer()\n",
    "    tokenized_doc = tokenized_doc.apply(lambda x: [porter_stemmer.stem(item) for item in x])\n",
    "\n",
    "    print(\"Detokenize\")\n",
    "    detokenized_doc = []\n",
    "    for i in range(len(source_essay)):\n",
    "        t = ' '.join(tokenized_doc[i])\n",
    "        detokenized_doc.append(t)\n",
    "\n",
    "    source_essay['essay'] = detokenized_doc\n",
    "\n",
    "    return source_essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocess for tokenization\n",
      "Tokenization Start\n",
      "Removing Stop Words\n",
      "Word Stemming\n",
      "Detokenize\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mark Anthony Mamauag\\AppData\\Local\\Temp\\ipykernel_3176\\213839504.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  source_essay['essay'] = source_essay['essay'].str.replace(\"[^a-zA-Z#]\", \" \")\n"
     ]
    }
   ],
   "source": [
    "cleaned_source_essay = clean_source_essay(source_essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay</th>\n",
       "      <th>actual_score</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>grammar_errors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mani obstacl builder face attempt dirig dock e...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.560976</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>start would mani problem allow dirig dock num ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.733333</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>builder empir state build face mani obstacl at...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.491124</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>passag moor mast marcia amid cap builder empir...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.417085</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>builder empir state build face mani obstacl at...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.654321</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>want tell go attempt allow dirig dock well tel...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.177215</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>empir state build conceiv plan world tallest b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>parent origin cuba arriv unit state live year ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saeng teenag girl famili move unit state vietn...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>forget old say never take candi stranger bette...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1804 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  essay  actual_score  \\\n",
       "0     mani obstacl builder face attempt dirig dock e...           2.0   \n",
       "1     start would mani problem allow dirig dock num ...           3.0   \n",
       "2     builder empir state build face mani obstacl at...           4.0   \n",
       "3     passag moor mast marcia amid cap builder empir...           1.0   \n",
       "4     builder empir state build face mani obstacl at...           3.0   \n",
       "...                                                 ...           ...   \n",
       "1799  want tell go attempt allow dirig dock well tel...           2.0   \n",
       "0     empir state build conceiv plan world tallest b...           NaN   \n",
       "1     parent origin cuba arriv unit state live year ...           NaN   \n",
       "2     saeng teenag girl famili move unit state vietn...           NaN   \n",
       "3     forget old say never take candi stranger bette...           NaN   \n",
       "\n",
       "      word_count  unique_word_count  sentence_count  avg_word_len  \\\n",
       "0          134.0               90.0             6.0      4.560976   \n",
       "1          201.0              116.0             9.0      4.733333   \n",
       "2          180.0              104.0             8.0      4.491124   \n",
       "3          213.0              118.0             7.0      4.417085   \n",
       "4          176.0               93.0            10.0      4.654321   \n",
       "...          ...                ...             ...           ...   \n",
       "1799       179.0               87.0             9.0      4.177215   \n",
       "0            NaN                NaN             NaN           NaN   \n",
       "1            NaN                NaN             NaN           NaN   \n",
       "2            NaN                NaN             NaN           NaN   \n",
       "3            NaN                NaN             NaN           NaN   \n",
       "\n",
       "      grammar_errors  \n",
       "0                3.0  \n",
       "1                2.0  \n",
       "2                2.0  \n",
       "3               12.0  \n",
       "4                1.0  \n",
       "...              ...  \n",
       "1799             7.0  \n",
       "0                NaN  \n",
       "1                NaN  \n",
       "2                NaN  \n",
       "3                NaN  \n",
       "\n",
       "[1804 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = [main_df, cleaned_source_essay]\n",
    "combined_df = pd.concat(frames)\n",
    "\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay</th>\n",
       "      <th>actual_score</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>grammar_errors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mani obstacl builder face attempt dirig dock e...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.560976</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>start would mani problem allow dirig dock num ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.733333</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>builder empir state build face mani obstacl at...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.491124</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>passag moor mast marcia amid cap builder empir...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.417085</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>builder empir state build face mani obstacl at...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.654321</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>want tell go attempt allow dirig dock well tel...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.177215</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>empir state build conceiv plan world tallest b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>parent origin cuba arriv unit state live year ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saeng teenag girl famili move unit state vietn...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>forget old say never take candi stranger bette...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1784 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  essay  actual_score  \\\n",
       "0     mani obstacl builder face attempt dirig dock e...           2.0   \n",
       "1     start would mani problem allow dirig dock num ...           3.0   \n",
       "2     builder empir state build face mani obstacl at...           4.0   \n",
       "3     passag moor mast marcia amid cap builder empir...           1.0   \n",
       "4     builder empir state build face mani obstacl at...           3.0   \n",
       "...                                                 ...           ...   \n",
       "1799  want tell go attempt allow dirig dock well tel...           2.0   \n",
       "0     empir state build conceiv plan world tallest b...           NaN   \n",
       "1     parent origin cuba arriv unit state live year ...           NaN   \n",
       "2     saeng teenag girl famili move unit state vietn...           NaN   \n",
       "3     forget old say never take candi stranger bette...           NaN   \n",
       "\n",
       "      word_count  unique_word_count  sentence_count  avg_word_len  \\\n",
       "0          134.0               90.0             6.0      4.560976   \n",
       "1          201.0              116.0             9.0      4.733333   \n",
       "2          180.0              104.0             8.0      4.491124   \n",
       "3          213.0              118.0             7.0      4.417085   \n",
       "4          176.0               93.0            10.0      4.654321   \n",
       "...          ...                ...             ...           ...   \n",
       "1799       179.0               87.0             9.0      4.177215   \n",
       "0            NaN                NaN             NaN           NaN   \n",
       "1            NaN                NaN             NaN           NaN   \n",
       "2            NaN                NaN             NaN           NaN   \n",
       "3            NaN                NaN             NaN           NaN   \n",
       "\n",
       "      grammar_errors  \n",
       "0                3.0  \n",
       "1                2.0  \n",
       "2                2.0  \n",
       "3               12.0  \n",
       "4                1.0  \n",
       "...              ...  \n",
       "1799             7.0  \n",
       "0                NaN  \n",
       "1                NaN  \n",
       "2                NaN  \n",
       "3                NaN  \n",
       "\n",
       "[1784 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_essay = combined_df[combined_df['actual_score'] >= 3]\n",
    "combined_essay = combined_essay.groupby('actual_score').sample(10, random_state=26)\n",
    "\n",
    "combined_df = combined_df.drop(index = combined_essay.index)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train TFIDF Matrix Shape: (20, 284)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tfidf_lsa_vectorizer = TfidfVectorizer(lowercase=True,\n",
    "                                        stop_words='english',\n",
    "                                        ngram_range = (1,3),\n",
    "                                        tokenizer = tokenizer.tokenize,\n",
    "                                        max_features=350,\n",
    "                                        max_df=0.8,\n",
    "                                        min_df=3)\n",
    "\n",
    "tfidf_lsa_matrix = tfidf_lsa_vectorizer.fit_transform(combined_essay[\"essay\"])\n",
    "print(f\"Train TFIDF Matrix Shape: {tfidf_lsa_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_lsa_model = TruncatedSVD(n_components=100,\n",
    "                         n_iter=200,\n",
    "                         random_state=69)\n",
    "    \n",
    "svd_lsa = svd_lsa_model.fit_transform(tfidf_lsa_matrix)\n",
    "normalized_svd = Normalizer(copy=False).fit_transform(svd_lsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lsa_score(essay):\n",
    "    essay_matrix = tfidf_lsa_vectorizer.transform([essay])\n",
    "\n",
    "    essay_svd = svd_lsa_model.transform(essay_matrix)\n",
    "    normalized_essay_svd = Normalizer(copy=False).fit_transform(essay_svd)\n",
    "\n",
    "    similarities = cosine_similarity(normalized_svd, normalized_essay_svd).max()\n",
    "\n",
    "    return similarities.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay</th>\n",
       "      <th>actual_score</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>grammar_errors</th>\n",
       "      <th>lsa_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mani obstacl builder face attempt dirig dock e...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.560976</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.589376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>start would mani problem allow dirig dock num ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.733333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.658643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>builder empir state build face mani obstacl at...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.491124</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.770081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>passag moor mast marcia amid cap builder empir...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.417085</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.620654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>builder empir state build face mani obstacl at...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.654321</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.772386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>want tell go attempt allow dirig dock well tel...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.177215</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.645588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>empir state build conceiv plan world tallest b...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>parent origin cuba arriv unit state live year ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.609972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saeng teenag girl famili move unit state vietn...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.462469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>forget old say never take candi stranger bette...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1784 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  essay  actual_score  \\\n",
       "0     mani obstacl builder face attempt dirig dock e...           2.0   \n",
       "1     start would mani problem allow dirig dock num ...           3.0   \n",
       "2     builder empir state build face mani obstacl at...           4.0   \n",
       "3     passag moor mast marcia amid cap builder empir...           1.0   \n",
       "4     builder empir state build face mani obstacl at...           3.0   \n",
       "...                                                 ...           ...   \n",
       "1799  want tell go attempt allow dirig dock well tel...           2.0   \n",
       "0     empir state build conceiv plan world tallest b...           0.0   \n",
       "1     parent origin cuba arriv unit state live year ...           0.0   \n",
       "2     saeng teenag girl famili move unit state vietn...           0.0   \n",
       "3     forget old say never take candi stranger bette...           0.0   \n",
       "\n",
       "      word_count  unique_word_count  sentence_count  avg_word_len  \\\n",
       "0          134.0               90.0             6.0      4.560976   \n",
       "1          201.0              116.0             9.0      4.733333   \n",
       "2          180.0              104.0             8.0      4.491124   \n",
       "3          213.0              118.0             7.0      4.417085   \n",
       "4          176.0               93.0            10.0      4.654321   \n",
       "...          ...                ...             ...           ...   \n",
       "1799       179.0               87.0             9.0      4.177215   \n",
       "0            0.0                0.0             0.0      0.000000   \n",
       "1            0.0                0.0             0.0      0.000000   \n",
       "2            0.0                0.0             0.0      0.000000   \n",
       "3            0.0                0.0             0.0      0.000000   \n",
       "\n",
       "      grammar_errors  lsa_score  \n",
       "0                3.0   0.589376  \n",
       "1                2.0   0.658643  \n",
       "2                2.0   0.770081  \n",
       "3               12.0   0.620654  \n",
       "4                1.0   0.772386  \n",
       "...              ...        ...  \n",
       "1799             7.0   0.645588  \n",
       "0                0.0   0.693081  \n",
       "1                0.0   0.609972  \n",
       "2                0.0   0.462469  \n",
       "3                0.0   0.778578  \n",
       "\n",
       "[1784 rows x 8 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df['lsa_score'] = combined_df['essay'].apply(lsa_score)\n",
    "combined_df = combined_df.fillna(0)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train TFIDF Matrix Shape: (1784, 6124)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# VECTORIZER FOR: Training data\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tfidf_vectorizer = TfidfVectorizer(lowercase=True,\n",
    "                                   stop_words='english',\n",
    "                                   ngram_range = (1,3),\n",
    "                                   tokenizer = tokenizer.tokenize,\n",
    "                                   max_features=10000,\n",
    "                                   max_df=0.8,\n",
    "                                   min_df=5)\n",
    "\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(combined_df[\"essay\"])\n",
    "print(f\"Train TFIDF Matrix Shape: {tfidf_matrix.shape}\")\n",
    "svd_model = TruncatedSVD(n_components=100,\n",
    "                         n_iter=200,\n",
    "                         random_state=69)\n",
    "\n",
    "svd = svd_model.fit_transform(tfidf_matrix)\n",
    "print(type(svd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_df_features = combined_df[['word_count', 'unique_word_count', 'sentence_count', 'avg_word_len', 'grammar_errors', 'lsa_score']]\n",
    "\n",
    "x_features = np.concatenate((x_df_features.to_numpy(), svd), axis=1)\n",
    "y_features = combined_df['actual_score'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_features, y_features, test_size = 0.2, train_size = 0.8, random_state = 420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Linear Regression Model\n",
      "Building SVR Model\n",
      "Building Decision Tree Model\n",
      "Building Bayesian Regressor\n",
      "Building AdaBoost Regressor\n",
      "Building Random Forest Regressor\n",
      "Building Gradient Boosting Regressor\n",
      "Building Logistic Regression Model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=10000, solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000, solver=&#x27;saga&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=10000, solver='saga')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Building Linear Regression Model\")\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(x_train, y_train)\n",
    "\n",
    "print(\"Building SVR Model\")\n",
    "svr_model = SVR()\n",
    "svr_model.fit(x_train, y_train)\n",
    "\n",
    "print(\"Building Decision Tree Model\")\n",
    "tree_model = DecisionTreeRegressor()\n",
    "tree_model.fit(x_train, y_train)\n",
    "\n",
    "print(\"Building Bayesian Regressor\")\n",
    "bayes_model = BayesianRidge()\n",
    "bayes_model.fit(x_train, y_train)\n",
    "\n",
    "print(\"Building AdaBoost Regressor\")\n",
    "ada_model = AdaBoostRegressor(n_estimators=100)\n",
    "ada_model.fit(x_train, y_train)\n",
    "\n",
    "print(\"Building Random Forest Regressor\")\n",
    "ran_model = RandomForestRegressor()\n",
    "ran_model.fit(x_train, y_train)\n",
    "\n",
    "print(\"Building Gradient Boosting Regressor\")\n",
    "grad_model = GradientBoostingRegressor(n_estimators=200)\n",
    "grad_model.fit(x_train, y_train)\n",
    "\n",
    "print(\"Building Logistic Regression Model\")\n",
    "log_model = LogisticRegression(solver=\"saga\", max_iter=10000)\n",
    "log_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [lr_model.predict(x_test),\n",
    "               svr_model.predict(x_test),\n",
    "               tree_model.predict(x_test),\n",
    "               bayes_model.predict(x_test),\n",
    "               ada_model.predict(x_test),\n",
    "               ran_model.predict(x_test),\n",
    "               grad_model.predict(x_test),\n",
    "               log_model.predict(x_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0\n",
      "Mean Absolute Error: 0.41013054420938155\n",
      "Mean Squared Error: 0.2682114130074931\n",
      "Root Mean Squared Error: 0.5178913138946174\n",
      "R2 score: 0.7092517106711576\n",
      "\n",
      "Model 1\n",
      "Mean Absolute Error: 0.4996685564394106\n",
      "Mean Squared Error: 0.4420318028633608\n",
      "Root Mean Squared Error: 0.6648547231263089\n",
      "R2 score: 0.5208257953293147\n",
      "\n",
      "Model 2\n",
      "Mean Absolute Error: 0.5378151260504201\n",
      "Mean Squared Error: 0.6218487394957983\n",
      "Root Mean Squared Error: 0.7885738643245782\n",
      "R2 score: 0.3258994641490175\n",
      "\n",
      "Model 3\n",
      "Mean Absolute Error: 0.4055375364743919\n",
      "Mean Squared Error: 0.260572049596366\n",
      "Root Mean Squared Error: 0.5104625839337943\n",
      "R2 score: 0.7175329833375245\n",
      "\n",
      "Model 4\n",
      "Mean Absolute Error: 0.4544088515643958\n",
      "Mean Squared Error: 0.33359512489924026\n",
      "Root Mean Squared Error: 0.5775769428389955\n",
      "R2 score: 0.6383740318679656\n",
      "\n",
      "Model 5\n",
      "Mean Absolute Error: 0.42523809523809525\n",
      "Mean Squared Error: 0.2948282913165266\n",
      "Root Mean Squared Error: 0.5429809308958525\n",
      "R2 score: 0.6803983082418984\n",
      "\n",
      "Model 6\n",
      "Mean Absolute Error: 0.40706354153970575\n",
      "Mean Squared Error: 0.25409299600008906\n",
      "Root Mean Squared Error: 0.5040763791332511\n",
      "R2 score: 0.7245564493730088\n",
      "\n",
      "Model 7\n",
      "Mean Absolute Error: 0.47058823529411764\n",
      "Mean Squared Error: 0.5658263305322129\n",
      "Root Mean Squared Error: 0.7522142849828185\n",
      "R2 score: 0.3866292421536105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, pred in enumerate(predictions):\n",
    "    mae = mean_absolute_error(y_test, pred)\n",
    "    mse = mean_squared_error(y_test, pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r_score = r2_score(y_test, pred)\n",
    "\n",
    "    print(f\"Model {idx}\")\n",
    "    print(f\"Mean Absolute Error: {mae}\")\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    print(f\"Root Mean Squared Error: {rmse}\")\n",
    "    print(f\"R2 score: {r_score}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = [cross_val_score(lr_model, x_train, y_train, cv=10).mean(),\n",
    "          cross_val_score(svr_model, x_train, y_train, cv=10).mean(),\n",
    "          cross_val_score(tree_model, x_train, y_train, cv=10).mean(),\n",
    "          cross_val_score(bayes_model, x_train, y_train, cv=10).mean(),\n",
    "          cross_val_score(ada_model, x_train, y_train, cv=10).mean(),\n",
    "          cross_val_score(ran_model, x_train, y_train, cv=10).mean(),\n",
    "          cross_val_score(grad_model, x_train, y_train, cv=10).mean(),\n",
    "          cross_val_score(log_model, x_train, y_train, cv=10).mean()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 0\n",
      "Overall Score: 0.7247304896062313\n",
      "\n",
      "Model: 1\n",
      "Overall Score: 0.515950047408619\n",
      "\n",
      "Model: 2\n",
      "Overall Score: 0.2850713848038679\n",
      "\n",
      "Model: 3\n",
      "Overall Score: 0.726816770861288\n",
      "\n",
      "Model: 4\n",
      "Overall Score: 0.6242683968268962\n",
      "\n",
      "Model: 5\n",
      "Overall Score: 0.664171638869558\n",
      "\n",
      "Model: 6\n",
      "Overall Score: 0.6947171034120672\n",
      "\n",
      "Model: 7\n",
      "Overall Score: 0.5837387964148528\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, score in enumerate(scores):\n",
    "    print(f\"Model: {idx}\")\n",
    "    print(f\"Overall Score: {score}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1d888b7e27d9d4f8fccada6ae7e4260d620cc5227dee391d6d7538000bf76028"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
